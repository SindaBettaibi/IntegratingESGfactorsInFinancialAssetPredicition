{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfab086-3eed-4d14-b5f5-c20bab7fa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline, BertTokenizer\n",
    "from importlib import reload\n",
    "import text_cleaner  # Import the module first\n",
    "text_cleaner = reload(text_cleaner)  # Reload the module\n",
    "from text_cleaner import TextCleaner  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93120603-59f2-46f2-b6a7-29a5071adaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('data/google-news-sentences.csv')\n",
    "df_news = df_news[['content','date']]\n",
    "df_reports = pd.read_csv('data/reports_sentences.csv')\n",
    "df_reports = df_reports[['Sentence','Year']]\n",
    "df_news.rename(columns={'content': 'Text', 'date': 'Date'}, inplace=True)\n",
    "df_reports.rename(columns={'Sentence': 'Text', 'Year': 'Date'}, inplace=True)\n",
    "# Concatenate the DataFrames\n",
    "df_combined = pd.concat([df_news, df_reports], ignore_index=True)\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee685e-fcdf-42d4-9302-4a984d44d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df_combined[df_combined['Text'].isna()]\n",
    "df_combined.dropna(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c53e9-c669-46f4-a56c-3de27a0b5907",
   "metadata": {},
   "source": [
    "## Pre-trained transformer: ESGBert\n",
    "### Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ffac1-7ba3-4288-8d89-ee855dd99ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environmental model\n",
    "env_model_name = \"ESGBERT/EnvironmentalBERT-environmental\"\n",
    "env_tokenizer = AutoTokenizer.from_pretrained(env_model_name)\n",
    "env_model = AutoModelForSequenceClassification.from_pretrained(env_model_name)\n",
    "pipe_env = pipeline(\"text-classification\", model=env_model, tokenizer=env_tokenizer)\n",
    "\n",
    "# Social model\n",
    "soc_model_name = \"ESGBERT/SocialBERT-social\"\n",
    "soc_tokenizer = AutoTokenizer.from_pretrained(soc_model_name)\n",
    "soc_model = AutoModelForSequenceClassification.from_pretrained(soc_model_name)\n",
    "pipe_soc = pipeline(\"text-classification\", model=soc_model, tokenizer=soc_tokenizer)\n",
    "\n",
    "# Governance model\n",
    "gov_model_name = \"ESGBERT/GovernanceBERT-governance\"\n",
    "gov_tokenizer = AutoTokenizer.from_pretrained(gov_model_name)\n",
    "gov_model = AutoModelForSequenceClassification.from_pretrained(gov_model_name)\n",
    "pipe_gov = pipeline(\"text-classification\", model=gov_model, tokenizer=gov_tokenizer)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3e3e9-f3dc-483c-a79e-1d6b117d50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_long_sentence(sentence, max_length=512):\n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return len(tokens) > max_length\n",
    "# Apply the function to the 'text' column\n",
    "df_combined['is_long'] = df_combined['Text'].apply(is_long_sentence)\n",
    "df_combined = df_combined[df_combined['is_long']==False]\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe92d2-4975-489c-b37d-e34446708bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner() \n",
    "# Apply the text-cleaning methods\n",
    "df_combined['Text'] = df_combined['Text'].apply(cleaner.remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d6d97-29f0-48c5-b782-3ee0127eb84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    # Apply each model\n",
    "    env_result = pipe_env(text)\n",
    "    soc_result = pipe_soc(text)\n",
    "    gov_result = pipe_gov(text)\n",
    "\n",
    "    # Extract the scores and labels, adjusting for 'none' predictions\n",
    "    env_score = env_result[0]['score'] if env_result and env_result[0]['label'] != 'none' else 0\n",
    "    soc_score = soc_result[0]['score'] if soc_result and soc_result[0]['label'] != 'none' else 0\n",
    "    gov_score = gov_result[0]['score'] if gov_result and gov_result[0]['label'] != 'none' else 0\n",
    "\n",
    "    # Create a dictionary of scores with their corresponding labels\n",
    "    scores = {\n",
    "        'Environmental': env_score,\n",
    "        'Social': soc_score,\n",
    "        'Governance': gov_score\n",
    "    }\n",
    "\n",
    "    # Check if all scores are zero or if 'none' condition affected all\n",
    "    if all(score == 0 for score in scores.values()):\n",
    "        return 'General'  # or 'None' or any other default category\n",
    "\n",
    "    # Determine the category with the highest score\n",
    "    max_category = max(scores, key=scores.get)\n",
    "\n",
    "    return max_category\n",
    "\n",
    "# Assuming test_df is your DataFrame and 'Text' is the column with text to classify\n",
    "test_df['ESG_Category'] = test_df['Text'].apply(classify_text)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c334ec9-2d20-469e-abb2-0658565f26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('data/labeled_esg_text.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
